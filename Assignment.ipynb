{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a href=\"http://cocl.us/pytorch_link_top\">\n    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n</a> "},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"},{"metadata":{},"cell_type":"markdown","source":"<h1><h1>Pre-trained-Models with PyTorch </h1>"},{"metadata":{},"cell_type":"markdown","source":"In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n<ul>\n<li>change the output layer</li>\n<li> train the model</li> \n<li>  identify  several  misclassified samples</li> \n </ul>\nYou will take several screenshots of your work and share your notebook. "},{"metadata":{},"cell_type":"markdown","source":"<h2>Table of Contents</h2>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n\n<ul>\n    <li><a href=\"#download_data\"> Download Data</a></li>\n    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n    <li><a href=\"#data_class\"> Dataset Class</a></li>\n    <li><a href=\"#Question_1\">Question 1</a></li>\n    <li><a href=\"#Question_2\">Question 2</a></li>\n    <li><a href=\"#Question_3\">Question 3</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>120 min</strong></p>\n </div>\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"download_data\">Download Data</h2>"},{"metadata":{},"cell_type":"markdown","source":"Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"},{"metadata":{"trusted":false},"cell_type":"code","source":"!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip ","execution_count":1,"outputs":[{"output_type":"stream","text":"--2020-06-05 10:49:28--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2598656062 (2.4G) [application/zip]\nSaving to: ‘Positive_tensors.zip.1’\n\n100%[====================================>] 2,598,656,062 38.3MB/s   in 65s    \n\n2020-06-05 10:50:33 (38.4 MB/s) - ‘Positive_tensors.zip.1’ saved [2598656062/2598656062]\n\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"!unzip -q Positive_tensors.zip ","execution_count":2,"outputs":[{"output_type":"stream","text":"replace Positive_tensors/5114.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n!unzip -q Negative_tensors.zip","execution_count":3,"outputs":[{"output_type":"stream","text":"--2020-06-05 10:52:47--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2111408108 (2.0G) [application/zip]\nSaving to: ‘Negative_tensors.zip.1’\n\n100%[====================================>] 2,111,408,108 35.8MB/s   in 55s    \n\n2020-06-05 10:53:43 (36.6 MB/s) - ‘Negative_tensors.zip.1’ saved [2111408108/2111408108]\n\nreplace Negative_tensors/5114.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We will install torchvision:"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install h5py","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting h5py\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 3.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.7 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from h5py) (1.18.4)\nRequirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from h5py) (1.15.0)\nInstalling collected packages: h5py\nSuccessfully installed h5py-2.10.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"},{"metadata":{},"cell_type":"markdown","source":"The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# These are the libraries will be used for this lab.\nimport torchvision.models as models\nfrom PIL import Image\nimport pandas\nfrom torchvision import transforms\nimport torch.nn as nn\nimport time\nimport torch \nimport matplotlib.pylab as plt\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\nimport os\nimport glob\ntorch.manual_seed(0)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<torch._C.Generator at 0x7fbd2a9a1150>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import imshow\nimport matplotlib.pylab as plt\nfrom PIL import Image\nimport pandas as pd\nimport os","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<!--Empty Space for separating topics-->"},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"data_class\">Dataset Class</h2>"},{"metadata":{},"cell_type":"markdown","source":" This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create your own dataset object\n\nclass Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"\"\n        positive=\"Positive_tensors\"\n        negative='Negative_tensors'\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)     \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n               \n        image=torch.load(self.all_files[idx])\n        y=self.Y[idx]\n                  \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y\n    \nprint(\"done\")","execution_count":5,"outputs":[{"output_type":"stream","text":"done\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We create two dataset objects, one for the training data and one for the validation data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = Dataset(train=True)\nvalidation_dataset = Dataset(train=False)\nprint(\"done\")","execution_count":6,"outputs":[{"output_type":"stream","text":"done\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"Question_1\">Question 1</h2>"},{"metadata":{},"cell_type":"markdown","source":"<b>Prepare a pre-trained resnet18 model :</b>"},{"metadata":{},"cell_type":"markdown","source":"<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1: Load the pre-trained model resnet18\n\nimport torchvision.models as models\n\nmodel = models.resnet18(pretrained=True)\nmodel\n# Type your code here","execution_count":7,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/jovyan/.cache/torch/checkpoints/resnet18-5c106cde.pth\n100.0%\n","name":"stderr"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2: Set the parameter cannot be trained for the pre-trained model\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Type your code here","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "},{"metadata":{},"cell_type":"markdown","source":"<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Linear(512, 2)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":10,"outputs":[{"output_type":"stream","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"Question_2\">Question 2: Train the Model</h2>"},{"metadata":{},"cell_type":"markdown","source":"In this question you will train your, model:"},{"metadata":{},"cell_type":"markdown","source":"<b>Step 1</b>: Create a cross entropy criterion function "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1: Create the loss function\n\ncriterion = nn.CrossEntropyLoss()\n# Type your code here","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Step 3</b>: Use the following optimizer to minimize the loss "},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<!--Empty Space for separating topics-->"},{"metadata":{},"cell_type":"markdown","source":"**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 1\nloss_list = []\naccuracy_list = []\naccuracy = 0\ncorrect = 0\nN_test = len(validation_dataset)\nN_train = len(train_dataset)\nstart_time = time.time()\n#n_epochs\n\nprint(\"Number of items in training set : \", N_train)\nprint(\"Number of items in testing set : \", N_test)\n\nrunning_loss = 0\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    for i, (x, y) in enumerate(train_loader):        \n        print('-' * 30)\n        print('Iteration (train phase) {}/{}'.format(i+1, int(N_train/batch_size)))\n        i_start_time = time.time()\n        \n       \n            \n        # set model to train \n        model.train() \n        \n        # clear gradient \n        optimizer.zero_grad()\n     \n        # make a prediction \n        z = model(x)\n   \n        # calculate loss \n        loss = criterion(z, y) \n        # loss.requires_grad = True\n    \n        # calculate gradients of parameters \n        loss.backward()\n        \n        # update parameters \n        optimizer.step()\n        \n        loss_list.append(loss.data)\n        print(\"Finished in {} (s)\".format(time.time()-i_start_time))\n    # end for\n        \n    correct=0\n    for i, (x_test, y_test) in enumerate(validation_loader):\n        print('-' * 30)\n        print('Iteration (validation phase) {}/{}'.format(i+1, int(N_test/batch_size)))\n        i_start_time = time.time()\n        \n        x_test \n        y_test \n        \n        # set model to eval \n        model.eval()\n       \n        # make a prediction \n        z = model(x_test)\n        \n        # find max \n        _, yhat = torch.max(z.data, 1)\n       \n       \n        #Calculate misclassified  samples in mini-batch \n        #hint +=(yhat==y_test).sum().item()\n        correct += (yhat==y_test).sum().item()  \n        \n        print(\"Finished in {} (s)\".format(time.time()-i_start_time))\n    # end for\n    \n    accuracy=correct/N_test\n    print(\"Epoch %d - accuracy: %.3f\" % (epoch+1, accuracy))\n    \n    accuracy_list.append(accuracy)\n    print(\"-\" * 72)\n    \n    # Save model\n    model_file_path = \"resnet18_trained_model_epoch_{}.pth\".format(epoch+1)\n    torch.save(model.state_dict(), model_file_path)\n    \n    # Duration for epoch\n    print(\"Finished epoch {} in {} (s).\".format(epoch+1, time.time()-start_time))\n\n","execution_count":14,"outputs":[{"output_type":"stream","text":"Number of items in training set :  30000\nNumber of items in testing set :  10000\n------------------------------\nIteration (train phase) 1/300\nFinished in 19.73385214805603 (s)\n------------------------------\nIteration (train phase) 2/300\nFinished in 17.220933437347412 (s)\n------------------------------\nIteration (train phase) 3/300\nFinished in 19.19963312149048 (s)\n------------------------------\nIteration (train phase) 4/300\nFinished in 19.16611385345459 (s)\n------------------------------\nIteration (train phase) 5/300\nFinished in 17.894611597061157 (s)\n------------------------------\nIteration (train phase) 6/300\nFinished in 19.130944967269897 (s)\n------------------------------\nIteration (train phase) 7/300\nFinished in 19.098361253738403 (s)\n------------------------------\nIteration (train phase) 8/300\nFinished in 18.34673023223877 (s)\n------------------------------\nIteration (train phase) 9/300\nFinished in 17.619892120361328 (s)\n------------------------------\nIteration (train phase) 10/300\nFinished in 16.612069845199585 (s)\n------------------------------\nIteration (train phase) 11/300\nFinished in 17.215214014053345 (s)\n------------------------------\nIteration (train phase) 12/300\nFinished in 17.186901807785034 (s)\n------------------------------\nIteration (train phase) 13/300\nFinished in 16.427520990371704 (s)\n------------------------------\nIteration (train phase) 14/300\nFinished in 20.73098063468933 (s)\n------------------------------\nIteration (train phase) 15/300\nFinished in 19.590320587158203 (s)\n------------------------------\nIteration (train phase) 16/300\nFinished in 19.042643308639526 (s)\n------------------------------\nIteration (train phase) 17/300\nFinished in 16.979926109313965 (s)\n------------------------------\nIteration (train phase) 18/300\nFinished in 18.601606130599976 (s)\n------------------------------\nIteration (train phase) 19/300\nFinished in 20.132446765899658 (s)\n------------------------------\nIteration (train phase) 20/300\nFinished in 16.61375904083252 (s)\n------------------------------\nIteration (train phase) 21/300\nFinished in 18.1880521774292 (s)\n------------------------------\nIteration (train phase) 22/300\nFinished in 18.15293836593628 (s)\n------------------------------\nIteration (train phase) 23/300\nFinished in 17.1211998462677 (s)\n------------------------------\nIteration (train phase) 24/300\nFinished in 19.161177158355713 (s)\n------------------------------\nIteration (train phase) 25/300\nFinished in 19.033989191055298 (s)\n------------------------------\nIteration (train phase) 26/300\nFinished in 19.205512523651123 (s)\n------------------------------\nIteration (train phase) 27/300\nFinished in 19.54339838027954 (s)\n------------------------------\nIteration (train phase) 28/300\nFinished in 18.01365828514099 (s)\n------------------------------\nIteration (train phase) 29/300\nFinished in 18.87058138847351 (s)\n------------------------------\nIteration (train phase) 30/300\nFinished in 20.729620456695557 (s)\n------------------------------\nIteration (train phase) 31/300\nFinished in 17.219502449035645 (s)\n------------------------------\nIteration (train phase) 32/300\nFinished in 18.05089807510376 (s)\n------------------------------\nIteration (train phase) 33/300\nFinished in 16.818482398986816 (s)\n------------------------------\nIteration (train phase) 34/300\nFinished in 19.60142183303833 (s)\n------------------------------\nIteration (train phase) 35/300\nFinished in 20.135326385498047 (s)\n------------------------------\nIteration (train phase) 36/300\nFinished in 20.73873209953308 (s)\n------------------------------\nIteration (train phase) 37/300\nFinished in 18.439980506896973 (s)\n------------------------------\nIteration (train phase) 38/300\nFinished in 18.536160945892334 (s)\n------------------------------\nIteration (train phase) 39/300\nFinished in 17.798024654388428 (s)\n------------------------------\nIteration (train phase) 40/300\nFinished in 19.01029133796692 (s)\n------------------------------\nIteration (train phase) 41/300\nFinished in 19.09429168701172 (s)\n------------------------------\nIteration (train phase) 42/300\nFinished in 19.121793270111084 (s)\n------------------------------\nIteration (train phase) 43/300\nFinished in 18.69532585144043 (s)\n------------------------------\nIteration (train phase) 44/300\nFinished in 17.625487565994263 (s)\n------------------------------\nIteration (train phase) 45/300\nFinished in 18.7552547454834 (s)\n------------------------------\nIteration (train phase) 46/300\nFinished in 20.360578775405884 (s)\n------------------------------\nIteration (train phase) 47/300\nFinished in 20.920923233032227 (s)\n------------------------------\nIteration (train phase) 48/300\nFinished in 20.907890796661377 (s)\n------------------------------\nIteration (train phase) 49/300\nFinished in 20.523793935775757 (s)\n------------------------------\nIteration (train phase) 50/300\nFinished in 19.95599937438965 (s)\n------------------------------\nIteration (train phase) 51/300\nFinished in 19.542993307113647 (s)\n------------------------------\nIteration (train phase) 52/300\nFinished in 20.503239154815674 (s)\n------------------------------\nIteration (train phase) 53/300\nFinished in 19.402102947235107 (s)\n------------------------------\nIteration (train phase) 54/300\nFinished in 20.368444442749023 (s)\n------------------------------\nIteration (train phase) 55/300\nFinished in 20.798868656158447 (s)\n------------------------------\nIteration (train phase) 56/300\nFinished in 20.13442611694336 (s)\n------------------------------\nIteration (train phase) 57/300\nFinished in 20.345836400985718 (s)\n------------------------------\nIteration (train phase) 58/300\nFinished in 20.208516359329224 (s)\n------------------------------\nIteration (train phase) 59/300\nFinished in 21.128534078598022 (s)\n------------------------------\nIteration (train phase) 60/300\nFinished in 19.830031633377075 (s)\n------------------------------\nIteration (train phase) 61/300\nFinished in 20.271254301071167 (s)\n------------------------------\nIteration (train phase) 62/300\nFinished in 19.649404764175415 (s)\n------------------------------\nIteration (train phase) 63/300\nFinished in 17.902085781097412 (s)\n------------------------------\nIteration (train phase) 64/300\nFinished in 17.994081735610962 (s)\n------------------------------\nIteration (train phase) 65/300\nFinished in 16.257217407226562 (s)\n------------------------------\nIteration (train phase) 66/300\nFinished in 18.34941554069519 (s)\n------------------------------\nIteration (train phase) 67/300\nFinished in 18.54230523109436 (s)\n------------------------------\nIteration (train phase) 68/300\nFinished in 19.041962146759033 (s)\n------------------------------\nIteration (train phase) 69/300\nFinished in 19.09484577178955 (s)\n------------------------------\nIteration (train phase) 70/300\nFinished in 20.721014499664307 (s)\n------------------------------\nIteration (train phase) 71/300\nFinished in 19.35524296760559 (s)\n------------------------------\nIteration (train phase) 72/300\nFinished in 18.22301936149597 (s)\n------------------------------\nIteration (train phase) 73/300\nFinished in 17.315753936767578 (s)\n------------------------------\nIteration (train phase) 74/300\nFinished in 17.669647932052612 (s)\n------------------------------\nIteration (train phase) 75/300\nFinished in 17.865506172180176 (s)\n------------------------------\nIteration (train phase) 76/300\nFinished in 17.742990016937256 (s)\n------------------------------\nIteration (train phase) 77/300\nFinished in 19.93674397468567 (s)\n------------------------------\nIteration (train phase) 78/300\nFinished in 20.51534128189087 (s)\n------------------------------\nIteration (train phase) 79/300\nFinished in 20.504613637924194 (s)\n------------------------------\nIteration (train phase) 80/300\nFinished in 20.61813473701477 (s)\n------------------------------\nIteration (train phase) 81/300\nFinished in 20.337849140167236 (s)\n------------------------------\nIteration (train phase) 82/300\nFinished in 18.645738124847412 (s)\n------------------------------\nIteration (train phase) 83/300\nFinished in 17.85784888267517 (s)\n------------------------------\nIteration (train phase) 84/300\nFinished in 18.161679983139038 (s)\n------------------------------\nIteration (train phase) 85/300\n","name":"stdout"},{"output_type":"stream","text":"Finished in 16.957188844680786 (s)\n------------------------------\nIteration (train phase) 86/300\nFinished in 17.163926362991333 (s)\n------------------------------\nIteration (train phase) 87/300\nFinished in 16.138959646224976 (s)\n------------------------------\nIteration (train phase) 88/300\nFinished in 17.730636596679688 (s)\n------------------------------\nIteration (train phase) 89/300\nFinished in 20.403809070587158 (s)\n------------------------------\nIteration (train phase) 90/300\nFinished in 20.455953121185303 (s)\n------------------------------\nIteration (train phase) 91/300\nFinished in 20.710699319839478 (s)\n------------------------------\nIteration (train phase) 92/300\nFinished in 21.322311401367188 (s)\n------------------------------\nIteration (train phase) 93/300\nFinished in 20.63195300102234 (s)\n------------------------------\nIteration (train phase) 94/300\nFinished in 19.65715503692627 (s)\n------------------------------\nIteration (train phase) 95/300\nFinished in 19.96153163909912 (s)\n------------------------------\nIteration (train phase) 96/300\nFinished in 20.37535572052002 (s)\n------------------------------\nIteration (train phase) 97/300\nFinished in 20.040847539901733 (s)\n------------------------------\nIteration (train phase) 98/300\nFinished in 20.55558204650879 (s)\n------------------------------\nIteration (train phase) 99/300\nFinished in 20.050045013427734 (s)\n------------------------------\nIteration (train phase) 100/300\nFinished in 20.28834867477417 (s)\n------------------------------\nIteration (train phase) 101/300\nFinished in 20.660341024398804 (s)\n------------------------------\nIteration (train phase) 102/300\nFinished in 20.26058316230774 (s)\n------------------------------\nIteration (train phase) 103/300\nFinished in 20.4647479057312 (s)\n------------------------------\nIteration (train phase) 104/300\nFinished in 20.317772388458252 (s)\n------------------------------\nIteration (train phase) 105/300\nFinished in 19.996546030044556 (s)\n------------------------------\nIteration (train phase) 106/300\nFinished in 20.65961980819702 (s)\n------------------------------\nIteration (train phase) 107/300\nFinished in 20.557860136032104 (s)\n------------------------------\nIteration (train phase) 108/300\nFinished in 20.685290336608887 (s)\n------------------------------\nIteration (train phase) 109/300\nFinished in 19.967529773712158 (s)\n------------------------------\nIteration (train phase) 110/300\nFinished in 20.86726951599121 (s)\n------------------------------\nIteration (train phase) 111/300\nFinished in 20.753843784332275 (s)\n------------------------------\nIteration (train phase) 112/300\nFinished in 20.170671701431274 (s)\n------------------------------\nIteration (train phase) 113/300\nFinished in 20.566341638565063 (s)\n------------------------------\nIteration (train phase) 114/300\nFinished in 20.423203468322754 (s)\n------------------------------\nIteration (train phase) 115/300\nFinished in 20.978798389434814 (s)\n------------------------------\nIteration (train phase) 116/300\nFinished in 20.927164793014526 (s)\n------------------------------\nIteration (train phase) 117/300\nFinished in 20.34936833381653 (s)\n------------------------------\nIteration (train phase) 118/300\nFinished in 20.867616415023804 (s)\n------------------------------\nIteration (train phase) 119/300\nFinished in 21.052223443984985 (s)\n------------------------------\nIteration (train phase) 120/300\nFinished in 20.78893232345581 (s)\n------------------------------\nIteration (train phase) 121/300\nFinished in 21.048933267593384 (s)\n------------------------------\nIteration (train phase) 122/300\nFinished in 20.149125337600708 (s)\n------------------------------\nIteration (train phase) 123/300\nFinished in 20.737512350082397 (s)\n------------------------------\nIteration (train phase) 124/300\nFinished in 20.654632568359375 (s)\n------------------------------\nIteration (train phase) 125/300\nFinished in 20.99170970916748 (s)\n------------------------------\nIteration (train phase) 126/300\nFinished in 21.271337270736694 (s)\n------------------------------\nIteration (train phase) 127/300\nFinished in 21.154792308807373 (s)\n------------------------------\nIteration (train phase) 128/300\nFinished in 21.19600749015808 (s)\n------------------------------\nIteration (train phase) 129/300\nFinished in 21.220881938934326 (s)\n------------------------------\nIteration (train phase) 130/300\nFinished in 21.245039701461792 (s)\n------------------------------\nIteration (train phase) 131/300\nFinished in 21.57945942878723 (s)\n------------------------------\nIteration (train phase) 132/300\nFinished in 20.828287839889526 (s)\n------------------------------\nIteration (train phase) 133/300\nFinished in 21.059876203536987 (s)\n------------------------------\nIteration (train phase) 134/300\nFinished in 21.165725708007812 (s)\n------------------------------\nIteration (train phase) 135/300\nFinished in 21.040079593658447 (s)\n------------------------------\nIteration (train phase) 136/300\nFinished in 20.64331579208374 (s)\n------------------------------\nIteration (train phase) 137/300\nFinished in 21.33335518836975 (s)\n------------------------------\nIteration (train phase) 138/300\nFinished in 20.97333788871765 (s)\n------------------------------\nIteration (train phase) 139/300\nFinished in 20.787542819976807 (s)\n------------------------------\nIteration (train phase) 140/300\nFinished in 22.092869997024536 (s)\n------------------------------\nIteration (train phase) 141/300\nFinished in 21.85611844062805 (s)\n------------------------------\nIteration (train phase) 142/300\nFinished in 21.87609338760376 (s)\n------------------------------\nIteration (train phase) 143/300\nFinished in 22.0920729637146 (s)\n------------------------------\nIteration (train phase) 144/300\nFinished in 23.586252450942993 (s)\n------------------------------\nIteration (train phase) 145/300\nFinished in 21.250373125076294 (s)\n------------------------------\nIteration (train phase) 146/300\nFinished in 20.849572896957397 (s)\n------------------------------\nIteration (train phase) 147/300\nFinished in 21.014460563659668 (s)\n------------------------------\nIteration (train phase) 148/300\nFinished in 21.08486580848694 (s)\n------------------------------\nIteration (train phase) 149/300\nFinished in 21.340301275253296 (s)\n------------------------------\nIteration (train phase) 150/300\nFinished in 21.22642469406128 (s)\n------------------------------\nIteration (train phase) 151/300\nFinished in 21.376681089401245 (s)\n------------------------------\nIteration (train phase) 152/300\nFinished in 21.63909888267517 (s)\n------------------------------\nIteration (train phase) 153/300\nFinished in 21.8486168384552 (s)\n------------------------------\nIteration (train phase) 154/300\nFinished in 21.482072830200195 (s)\n------------------------------\nIteration (train phase) 155/300\nFinished in 21.73310923576355 (s)\n------------------------------\nIteration (train phase) 156/300\nFinished in 20.742546558380127 (s)\n------------------------------\nIteration (train phase) 157/300\nFinished in 21.05260467529297 (s)\n------------------------------\nIteration (train phase) 158/300\nFinished in 21.027561902999878 (s)\n------------------------------\nIteration (train phase) 159/300\nFinished in 21.43449878692627 (s)\n------------------------------\nIteration (train phase) 160/300\nFinished in 20.888965129852295 (s)\n------------------------------\nIteration (train phase) 161/300\nFinished in 20.930806398391724 (s)\n------------------------------\nIteration (train phase) 162/300\nFinished in 20.711106538772583 (s)\n------------------------------\nIteration (train phase) 163/300\nFinished in 21.01774787902832 (s)\n------------------------------\nIteration (train phase) 164/300\nFinished in 21.166370630264282 (s)\n------------------------------\nIteration (train phase) 165/300\nFinished in 21.272908449172974 (s)\n------------------------------\nIteration (train phase) 166/300\nFinished in 20.84807801246643 (s)\n------------------------------\nIteration (train phase) 167/300\nFinished in 21.57389211654663 (s)\n------------------------------\nIteration (train phase) 168/300\nFinished in 20.86099672317505 (s)\n------------------------------\nIteration (train phase) 169/300\nFinished in 21.09304118156433 (s)\n","name":"stdout"},{"output_type":"stream","text":"------------------------------\nIteration (train phase) 170/300\nFinished in 21.05348491668701 (s)\n------------------------------\nIteration (train phase) 171/300\nFinished in 21.35026264190674 (s)\n------------------------------\nIteration (train phase) 172/300\nFinished in 21.935349702835083 (s)\n------------------------------\nIteration (train phase) 173/300\nFinished in 21.57241702079773 (s)\n------------------------------\nIteration (train phase) 174/300\nFinished in 21.80659031867981 (s)\n------------------------------\nIteration (train phase) 175/300\nFinished in 21.21816897392273 (s)\n------------------------------\nIteration (train phase) 176/300\nFinished in 21.259270429611206 (s)\n------------------------------\nIteration (train phase) 177/300\nFinished in 21.012547254562378 (s)\n------------------------------\nIteration (train phase) 178/300\nFinished in 21.064968585968018 (s)\n------------------------------\nIteration (train phase) 179/300\nFinished in 21.579907655715942 (s)\n------------------------------\nIteration (train phase) 180/300\nFinished in 21.729392528533936 (s)\n------------------------------\nIteration (train phase) 181/300\nFinished in 22.584864377975464 (s)\n------------------------------\nIteration (train phase) 182/300\nFinished in 23.109471082687378 (s)\n------------------------------\nIteration (train phase) 183/300\nFinished in 23.782177448272705 (s)\n------------------------------\nIteration (train phase) 184/300\nFinished in 22.337400674819946 (s)\n------------------------------\nIteration (train phase) 185/300\nFinished in 23.617530822753906 (s)\n------------------------------\nIteration (train phase) 186/300\nFinished in 21.875531435012817 (s)\n------------------------------\nIteration (train phase) 187/300\nFinished in 21.444109678268433 (s)\n------------------------------\nIteration (train phase) 188/300\nFinished in 21.38667321205139 (s)\n------------------------------\nIteration (train phase) 189/300\nFinished in 21.787082195281982 (s)\n------------------------------\nIteration (train phase) 190/300\nFinished in 22.545775413513184 (s)\n------------------------------\nIteration (train phase) 191/300\nFinished in 22.859035968780518 (s)\n------------------------------\nIteration (train phase) 192/300\nFinished in 22.97560143470764 (s)\n------------------------------\nIteration (train phase) 193/300\nFinished in 22.190111875534058 (s)\n------------------------------\nIteration (train phase) 194/300\nFinished in 23.02383828163147 (s)\n------------------------------\nIteration (train phase) 195/300\nFinished in 22.442896127700806 (s)\n------------------------------\nIteration (train phase) 196/300\nFinished in 23.37048649787903 (s)\n------------------------------\nIteration (train phase) 197/300\nFinished in 23.378854513168335 (s)\n------------------------------\nIteration (train phase) 198/300\nFinished in 22.84643054008484 (s)\n------------------------------\nIteration (train phase) 199/300\nFinished in 23.344217538833618 (s)\n------------------------------\nIteration (train phase) 200/300\nFinished in 24.94308376312256 (s)\n------------------------------\nIteration (train phase) 201/300\nFinished in 24.72404193878174 (s)\n------------------------------\nIteration (train phase) 202/300\nFinished in 23.351325273513794 (s)\n------------------------------\nIteration (train phase) 203/300\nFinished in 22.854234218597412 (s)\n------------------------------\nIteration (train phase) 204/300\nFinished in 23.02200174331665 (s)\n------------------------------\nIteration (train phase) 205/300\nFinished in 22.62290072441101 (s)\n------------------------------\nIteration (train phase) 206/300\nFinished in 22.526034355163574 (s)\n------------------------------\nIteration (train phase) 207/300\nFinished in 23.144193410873413 (s)\n------------------------------\nIteration (train phase) 208/300\nFinished in 22.901515007019043 (s)\n------------------------------\nIteration (train phase) 209/300\nFinished in 22.239821434020996 (s)\n------------------------------\nIteration (train phase) 210/300\nFinished in 21.954599142074585 (s)\n------------------------------\nIteration (train phase) 211/300\nFinished in 21.724084854125977 (s)\n------------------------------\nIteration (train phase) 212/300\nFinished in 21.6800377368927 (s)\n------------------------------\nIteration (train phase) 213/300\nFinished in 22.727996110916138 (s)\n------------------------------\nIteration (train phase) 214/300\nFinished in 22.700525522232056 (s)\n------------------------------\nIteration (train phase) 215/300\nFinished in 22.149935245513916 (s)\n------------------------------\nIteration (train phase) 216/300\nFinished in 21.22321105003357 (s)\n------------------------------\nIteration (train phase) 217/300\nFinished in 21.637226581573486 (s)\n------------------------------\nIteration (train phase) 218/300\nFinished in 21.582051515579224 (s)\n------------------------------\nIteration (train phase) 219/300\nFinished in 22.04540205001831 (s)\n------------------------------\nIteration (train phase) 220/300\nFinished in 21.914621353149414 (s)\n------------------------------\nIteration (train phase) 221/300\nFinished in 21.824514150619507 (s)\n------------------------------\nIteration (train phase) 222/300\nFinished in 21.319711446762085 (s)\n------------------------------\nIteration (train phase) 223/300\nFinished in 21.628159284591675 (s)\n------------------------------\nIteration (train phase) 224/300\nFinished in 21.657168865203857 (s)\n------------------------------\nIteration (train phase) 225/300\nFinished in 21.803178071975708 (s)\n------------------------------\nIteration (train phase) 226/300\nFinished in 21.140395402908325 (s)\n------------------------------\nIteration (train phase) 227/300\nFinished in 21.578990697860718 (s)\n------------------------------\nIteration (train phase) 228/300\nFinished in 21.86275291442871 (s)\n------------------------------\nIteration (train phase) 229/300\nFinished in 22.3810133934021 (s)\n------------------------------\nIteration (train phase) 230/300\nFinished in 22.31870126724243 (s)\n------------------------------\nIteration (train phase) 231/300\nFinished in 22.012009859085083 (s)\n------------------------------\nIteration (train phase) 232/300\nFinished in 22.928271055221558 (s)\n------------------------------\nIteration (train phase) 233/300\nFinished in 21.776764154434204 (s)\n------------------------------\nIteration (train phase) 234/300\nFinished in 21.98239827156067 (s)\n------------------------------\nIteration (train phase) 235/300\nFinished in 23.229519367218018 (s)\n------------------------------\nIteration (train phase) 236/300\nFinished in 22.4408917427063 (s)\n------------------------------\nIteration (train phase) 237/300\nFinished in 22.552030563354492 (s)\n------------------------------\nIteration (train phase) 238/300\nFinished in 22.998247623443604 (s)\n------------------------------\nIteration (train phase) 239/300\nFinished in 22.529277563095093 (s)\n------------------------------\nIteration (train phase) 240/300\nFinished in 23.346091985702515 (s)\n------------------------------\nIteration (train phase) 241/300\nFinished in 23.431431531906128 (s)\n------------------------------\nIteration (train phase) 242/300\nFinished in 22.928096532821655 (s)\n------------------------------\nIteration (train phase) 243/300\nFinished in 22.957368850708008 (s)\n------------------------------\nIteration (train phase) 244/300\nFinished in 23.301846504211426 (s)\n------------------------------\nIteration (train phase) 245/300\nFinished in 22.54517698287964 (s)\n------------------------------\nIteration (train phase) 246/300\nFinished in 22.51005744934082 (s)\n------------------------------\nIteration (train phase) 247/300\nFinished in 22.744906902313232 (s)\n------------------------------\nIteration (train phase) 248/300\nFinished in 22.360301971435547 (s)\n------------------------------\nIteration (train phase) 249/300\nFinished in 23.023191928863525 (s)\n------------------------------\nIteration (train phase) 250/300\nFinished in 22.852336168289185 (s)\n------------------------------\nIteration (train phase) 251/300\nFinished in 22.958876848220825 (s)\n------------------------------\nIteration (train phase) 252/300\nFinished in 23.072329998016357 (s)\n------------------------------\nIteration (train phase) 253/300\nFinished in 21.828184366226196 (s)\n","name":"stdout"},{"output_type":"stream","text":"------------------------------\nIteration (train phase) 254/300\nFinished in 21.66375732421875 (s)\n------------------------------\nIteration (train phase) 255/300\nFinished in 22.85721731185913 (s)\n------------------------------\nIteration (train phase) 256/300\nFinished in 22.63226628303528 (s)\n------------------------------\nIteration (train phase) 257/300\nFinished in 22.485120058059692 (s)\n------------------------------\nIteration (train phase) 258/300\nFinished in 22.887251377105713 (s)\n------------------------------\nIteration (train phase) 259/300\nFinished in 23.119926691055298 (s)\n------------------------------\nIteration (train phase) 260/300\nFinished in 22.914902210235596 (s)\n------------------------------\nIteration (train phase) 261/300\nFinished in 23.380180835723877 (s)\n------------------------------\nIteration (train phase) 262/300\nFinished in 23.8873929977417 (s)\n------------------------------\nIteration (train phase) 263/300\nFinished in 24.156233549118042 (s)\n------------------------------\nIteration (train phase) 264/300\nFinished in 24.123260021209717 (s)\n------------------------------\nIteration (train phase) 265/300\nFinished in 24.00666856765747 (s)\n------------------------------\nIteration (train phase) 266/300\nFinished in 23.91290783882141 (s)\n------------------------------\nIteration (train phase) 267/300\nFinished in 23.56426215171814 (s)\n------------------------------\nIteration (train phase) 268/300\nFinished in 24.244516372680664 (s)\n------------------------------\nIteration (train phase) 269/300\nFinished in 24.366190910339355 (s)\n------------------------------\nIteration (train phase) 270/300\nFinished in 23.853541374206543 (s)\n------------------------------\nIteration (train phase) 271/300\nFinished in 24.36953902244568 (s)\n------------------------------\nIteration (train phase) 272/300\nFinished in 24.393540620803833 (s)\n------------------------------\nIteration (train phase) 273/300\nFinished in 23.54578995704651 (s)\n------------------------------\nIteration (train phase) 274/300\nFinished in 24.122486352920532 (s)\n------------------------------\nIteration (train phase) 275/300\nFinished in 24.24943518638611 (s)\n------------------------------\nIteration (train phase) 276/300\nFinished in 23.51906156539917 (s)\n------------------------------\nIteration (train phase) 277/300\nFinished in 23.537468671798706 (s)\n------------------------------\nIteration (train phase) 278/300\nFinished in 23.75816535949707 (s)\n------------------------------\nIteration (train phase) 279/300\nFinished in 24.574060916900635 (s)\n------------------------------\nIteration (train phase) 280/300\nFinished in 24.011510610580444 (s)\n------------------------------\nIteration (train phase) 281/300\nFinished in 23.918853521347046 (s)\n------------------------------\nIteration (train phase) 282/300\nFinished in 24.434213638305664 (s)\n------------------------------\nIteration (train phase) 283/300\nFinished in 22.735177278518677 (s)\n------------------------------\nIteration (train phase) 284/300\nFinished in 24.257951974868774 (s)\n------------------------------\nIteration (train phase) 285/300\nFinished in 23.963523149490356 (s)\n------------------------------\nIteration (train phase) 286/300\nFinished in 23.618265390396118 (s)\n------------------------------\nIteration (train phase) 287/300\nFinished in 23.170650005340576 (s)\n------------------------------\nIteration (train phase) 288/300\nFinished in 24.026408910751343 (s)\n------------------------------\nIteration (train phase) 289/300\nFinished in 23.86886215209961 (s)\n------------------------------\nIteration (train phase) 290/300\nFinished in 23.79781985282898 (s)\n------------------------------\nIteration (train phase) 291/300\nFinished in 23.76234221458435 (s)\n------------------------------\nIteration (train phase) 292/300\nFinished in 23.624653577804565 (s)\n------------------------------\nIteration (train phase) 293/300\nFinished in 24.47935914993286 (s)\n------------------------------\nIteration (train phase) 294/300\nFinished in 24.296729564666748 (s)\n------------------------------\nIteration (train phase) 295/300\nFinished in 23.741175651550293 (s)\n------------------------------\nIteration (train phase) 296/300\nFinished in 23.617588996887207 (s)\n------------------------------\nIteration (train phase) 297/300\nFinished in 24.312145233154297 (s)\n------------------------------\nIteration (train phase) 298/300\nFinished in 25.172562837600708 (s)\n------------------------------\nIteration (train phase) 299/300\nFinished in 25.167653799057007 (s)\n------------------------------\nIteration (train phase) 300/300\nFinished in 25.388850688934326 (s)\n------------------------------\nIteration (validation phase) 1/100\nFinished in 21.082528829574585 (s)\n------------------------------\nIteration (validation phase) 2/100\nFinished in 21.331212043762207 (s)\n------------------------------\nIteration (validation phase) 3/100\nFinished in 21.395644903182983 (s)\n------------------------------\nIteration (validation phase) 4/100\nFinished in 20.809123754501343 (s)\n------------------------------\nIteration (validation phase) 5/100\nFinished in 20.904227256774902 (s)\n------------------------------\nIteration (validation phase) 6/100\nFinished in 21.60512065887451 (s)\n------------------------------\nIteration (validation phase) 7/100\nFinished in 21.20652985572815 (s)\n------------------------------\nIteration (validation phase) 8/100\nFinished in 22.04655885696411 (s)\n------------------------------\nIteration (validation phase) 9/100\nFinished in 22.18339443206787 (s)\n------------------------------\nIteration (validation phase) 10/100\nFinished in 21.54307985305786 (s)\n------------------------------\nIteration (validation phase) 11/100\nFinished in 22.12909483909607 (s)\n------------------------------\nIteration (validation phase) 12/100\nFinished in 21.317744731903076 (s)\n------------------------------\nIteration (validation phase) 13/100\nFinished in 21.623666048049927 (s)\n------------------------------\nIteration (validation phase) 14/100\nFinished in 22.231274843215942 (s)\n------------------------------\nIteration (validation phase) 15/100\nFinished in 21.676652908325195 (s)\n------------------------------\nIteration (validation phase) 16/100\nFinished in 21.40301823616028 (s)\n------------------------------\nIteration (validation phase) 17/100\nFinished in 22.160821676254272 (s)\n------------------------------\nIteration (validation phase) 18/100\nFinished in 22.46869969367981 (s)\n------------------------------\nIteration (validation phase) 19/100\nFinished in 22.047701835632324 (s)\n------------------------------\nIteration (validation phase) 20/100\nFinished in 33.39160895347595 (s)\n------------------------------\nIteration (validation phase) 21/100\nFinished in 38.009942054748535 (s)\n------------------------------\nIteration (validation phase) 22/100\nFinished in 23.224977254867554 (s)\n------------------------------\nIteration (validation phase) 23/100\nFinished in 21.981550455093384 (s)\n------------------------------\nIteration (validation phase) 24/100\nFinished in 21.329577922821045 (s)\n------------------------------\nIteration (validation phase) 25/100\nFinished in 21.936159133911133 (s)\n------------------------------\nIteration (validation phase) 26/100\nFinished in 22.44928216934204 (s)\n------------------------------\nIteration (validation phase) 27/100\nFinished in 21.461474895477295 (s)\n------------------------------\nIteration (validation phase) 28/100\nFinished in 21.8676118850708 (s)\n------------------------------\nIteration (validation phase) 29/100\nFinished in 21.348519802093506 (s)\n------------------------------\nIteration (validation phase) 30/100\nFinished in 21.114662408828735 (s)\n------------------------------\nIteration (validation phase) 31/100\nFinished in 21.117889404296875 (s)\n------------------------------\nIteration (validation phase) 32/100\nFinished in 20.796313524246216 (s)\n------------------------------\nIteration (validation phase) 33/100\nFinished in 21.73063087463379 (s)\n------------------------------\nIteration (validation phase) 34/100\nFinished in 21.286272048950195 (s)\n------------------------------\nIteration (validation phase) 35/100\nFinished in 21.44698476791382 (s)\n------------------------------\nIteration (validation phase) 36/100\n","name":"stdout"},{"output_type":"stream","text":"Finished in 21.233087062835693 (s)\n------------------------------\nIteration (validation phase) 37/100\nFinished in 21.209170818328857 (s)\n------------------------------\nIteration (validation phase) 38/100\nFinished in 22.18375062942505 (s)\n------------------------------\nIteration (validation phase) 39/100\nFinished in 21.416570901870728 (s)\n------------------------------\nIteration (validation phase) 40/100\nFinished in 21.502536058425903 (s)\n------------------------------\nIteration (validation phase) 41/100\nFinished in 21.47350287437439 (s)\n------------------------------\nIteration (validation phase) 42/100\nFinished in 20.084771156311035 (s)\n------------------------------\nIteration (validation phase) 43/100\nFinished in 19.607996940612793 (s)\n------------------------------\nIteration (validation phase) 44/100\nFinished in 20.058143377304077 (s)\n------------------------------\nIteration (validation phase) 45/100\nFinished in 20.610859394073486 (s)\n------------------------------\nIteration (validation phase) 46/100\nFinished in 20.090099334716797 (s)\n------------------------------\nIteration (validation phase) 47/100\nFinished in 19.74627923965454 (s)\n------------------------------\nIteration (validation phase) 48/100\nFinished in 19.97730326652527 (s)\n------------------------------\nIteration (validation phase) 49/100\nFinished in 19.764044284820557 (s)\n------------------------------\nIteration (validation phase) 50/100\nFinished in 19.54749035835266 (s)\n------------------------------\nIteration (validation phase) 51/100\nFinished in 20.43578600883484 (s)\n------------------------------\nIteration (validation phase) 52/100\nFinished in 19.518428087234497 (s)\n------------------------------\nIteration (validation phase) 53/100\nFinished in 19.731865167617798 (s)\n------------------------------\nIteration (validation phase) 54/100\nFinished in 19.15844488143921 (s)\n------------------------------\nIteration (validation phase) 55/100\nFinished in 19.780258893966675 (s)\n------------------------------\nIteration (validation phase) 56/100\nFinished in 19.543943166732788 (s)\n------------------------------\nIteration (validation phase) 57/100\nFinished in 20.298927783966064 (s)\n------------------------------\nIteration (validation phase) 58/100\nFinished in 19.597328186035156 (s)\n------------------------------\nIteration (validation phase) 59/100\nFinished in 20.143087148666382 (s)\n------------------------------\nIteration (validation phase) 60/100\nFinished in 19.54800510406494 (s)\n------------------------------\nIteration (validation phase) 61/100\nFinished in 19.18874192237854 (s)\n------------------------------\nIteration (validation phase) 62/100\nFinished in 19.36910605430603 (s)\n------------------------------\nIteration (validation phase) 63/100\nFinished in 18.944222688674927 (s)\n------------------------------\nIteration (validation phase) 64/100\nFinished in 18.771899223327637 (s)\n------------------------------\nIteration (validation phase) 65/100\nFinished in 19.044064044952393 (s)\n------------------------------\nIteration (validation phase) 66/100\nFinished in 20.791669607162476 (s)\n------------------------------\nIteration (validation phase) 67/100\nFinished in 21.353123903274536 (s)\n------------------------------\nIteration (validation phase) 68/100\nFinished in 22.329163074493408 (s)\n------------------------------\nIteration (validation phase) 69/100\nFinished in 21.89538812637329 (s)\n------------------------------\nIteration (validation phase) 70/100\nFinished in 20.806522369384766 (s)\n------------------------------\nIteration (validation phase) 71/100\nFinished in 20.64890193939209 (s)\n------------------------------\nIteration (validation phase) 72/100\nFinished in 21.012613773345947 (s)\n------------------------------\nIteration (validation phase) 73/100\nFinished in 20.55577301979065 (s)\n------------------------------\nIteration (validation phase) 74/100\nFinished in 21.096475839614868 (s)\n------------------------------\nIteration (validation phase) 75/100\nFinished in 20.64044427871704 (s)\n------------------------------\nIteration (validation phase) 76/100\nFinished in 21.79523491859436 (s)\n------------------------------\nIteration (validation phase) 77/100\nFinished in 20.829591274261475 (s)\n------------------------------\nIteration (validation phase) 78/100\nFinished in 20.413901329040527 (s)\n------------------------------\nIteration (validation phase) 79/100\nFinished in 20.546846628189087 (s)\n------------------------------\nIteration (validation phase) 80/100\nFinished in 20.771536111831665 (s)\n------------------------------\nIteration (validation phase) 81/100\nFinished in 20.70382833480835 (s)\n------------------------------\nIteration (validation phase) 82/100\nFinished in 20.972899675369263 (s)\n------------------------------\nIteration (validation phase) 83/100\nFinished in 21.227216720581055 (s)\n------------------------------\nIteration (validation phase) 84/100\nFinished in 20.787086963653564 (s)\n------------------------------\nIteration (validation phase) 85/100\nFinished in 21.003645658493042 (s)\n------------------------------\nIteration (validation phase) 86/100\nFinished in 20.506459951400757 (s)\n------------------------------\nIteration (validation phase) 87/100\nFinished in 20.885377407073975 (s)\n------------------------------\nIteration (validation phase) 88/100\nFinished in 20.948185205459595 (s)\n------------------------------\nIteration (validation phase) 89/100\nFinished in 20.497423887252808 (s)\n------------------------------\nIteration (validation phase) 90/100\nFinished in 20.793988943099976 (s)\n------------------------------\nIteration (validation phase) 91/100\nFinished in 20.736500024795532 (s)\n------------------------------\nIteration (validation phase) 92/100\nFinished in 20.840556144714355 (s)\n------------------------------\nIteration (validation phase) 93/100\nFinished in 20.3938090801239 (s)\n------------------------------\nIteration (validation phase) 94/100\nFinished in 20.803388118743896 (s)\n------------------------------\nIteration (validation phase) 95/100\nFinished in 20.555694103240967 (s)\n------------------------------\nIteration (validation phase) 96/100\nFinished in 20.030943393707275 (s)\n------------------------------\nIteration (validation phase) 97/100\nFinished in 20.86478614807129 (s)\n------------------------------\nIteration (validation phase) 98/100\nFinished in 20.62312388420105 (s)\n------------------------------\nIteration (validation phase) 99/100\nFinished in 20.906705379486084 (s)\n------------------------------\nIteration (validation phase) 100/100\nFinished in 20.79354238510132 (s)\nEpoch 1 - accuracy: 0.993\n------------------------------------------------------------------------\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'model_path' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-481d4f9d4335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mmodel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"resnet18_trained_model_epoch_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"0.9934"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()\n","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3gc5bX48e/RrnqvLrJsueKKC3IBUxMDBnID3CS0BNIJCSRc8iM3pNz0cEly0wgEYhISCAQHQnPAwUCwAYOb3KtsyZatavVeV3p/f8zseiWtbNlovJL2fJ5Hj3dnZnfPaK0583YxxqCUUip0hQU7AKWUUsGliUAppUKcJgKllApxmgiUUirEaSJQSqkQ5w52AKcrLS3NZGdnBzsMpZQaVrZu3VpljEkPtG/YJYLs7Gxyc3ODHYZSSg0rInK0v31aNaSUUiFOE4FSSoU4TQRKKRXiNBEopVSI00SglFIhThOBUkqFOEcTgYgsF5E8EckXkfsC7P+GiOywf/aISJeIpDgZk1JKqZ4cSwQi4gIeBq4CZgI3i8hM/2OMMb8wxswzxswDvgW8bYypcSKevPJG/m9NHjXNHU68vVJKDVtOlggWAfnGmMPGmA5gJXDtSY6/GXjGqWCOVDXx0Np8jje0OfURSik1LDmZCDKBIr/nxfa2PkQkBlgOPN/P/ttFJFdEcisrK88omJgIaxB1c7vnjF6vlFIjlZOJQAJs6285tP8A3uuvWsgYs8IYk2OMyUlPDzhVxinFRlqJoEkTgVJK9eBkIigGsvyejwNK+zn2JhysFgKIi/SWCLqc/BillBp2nEwEW4CpIjJRRCKwLvareh8kIonAJcDLDsZCbKQL0KohpZTqzbHZR40xHhG5C1gDuIDHjTF7ReQOe/+j9qHXA68bY5qdigX8SgQdmgiUUsqfo9NQG2NWA6t7bXu01/O/AH9xMg7QxmKllOpPyIwsjnCHEeEKo0nbCJRSqoeQSQRgtRNoiUAppXoKsUTg1kSglFK9hFQiiIt06zgCpZTqJaQSQUyEi5YObSNQSil/IZUIYrVEoJRSfYRUIojTNgKllOojpBKBNhYrpVRfIZUItLFYKaX6CqlE4G0sNqa/SVCVUir0hFQiiI104+k2tHu6gx2KUkoNGSGVCE5MRa3VQ0op5RVSiSBW1yRQSqk+QioRJERZiaCySdctVkopr5BKBAuzU3CFCWsPnNm6x0opNRKFVCJIjo1gUXYKa/aWBzsUpZQaMkIqEQBcOWsUhyqaOFbdEuxQlFJqSAi5RDBjTAIAx2o0ESilFIRgIkiNiwCgurk9yJEopdTQEHqJIDYSgOqmjiBHopRSQ4OjiUBElotInojki8h9/RxzqYjsEJG9IvK2k/EAJEaH4woTapo1ESilFIDbqTcWERfwMHA5UAxsEZFVxph9fsckAb8HlhtjjolIhlPxeIWFCckx4VRrIlBKKcDZEsEiIN8Yc9gY0wGsBK7tdcwtwAvGmGMAxpgKB+PxSY2NpLpJ2wiUUgqcTQSZQJHf82J7m79pQLKIrBORrSJyW6A3EpHbRSRXRHIrKz/4YLCU2AitGlJKKZuTiUACbOs9/7MbOA+4BrgS+B8RmdbnRcasMMbkGGNy0tPTP3BgKXGaCJRSysuxNgKsEkCW3/NxQGmAY6qMMc1As4i8A8wFDjoYF2mxEVRp1ZBSSgHOlgi2AFNFZKKIRAA3Aat6HfMycJGIuEUkBlgM7HcwJgBSYiNpaPPQ2aXrEiillGMlAmOMR0TuAtYALuBxY8xeEbnD3v+oMWa/iLwG7AK6gT8aY/Y4FZNXij2orLa5g4yEKKc/TimlhjQnq4YwxqwGVvfa9miv578AfuFkHL2lxVqJoKpJE4FSSoXcyGKAxJhwAOpbO4MciVJKBV9IJoL4SCsRNOmSlUopFZqJIM5eqaypXUsESikVkokg3psI2rREoJRSIZkI4uxF7Bs0ESilVGgmgkh3GOEu0TYCpZQiRBOBiBAfFa5VQ0opRYgmArCqhxrbtLFYKaVCOhFo1ZBSSoVwIoiPctOoVUNKKRXaiUBLBEopFcKJwGoj0ESglFKhmwi0RKCUUkAIJwLtPqqUUpaQTQRxkW46urr5r5XbqdVlK5VSISxkE4F3vqGXdpTy7wMVQY5GKaWCJ+QTAcCOotogRqKUUsEVsomgs8v4Hu8sqg9iJEopFVwhmwjOm5AMwNIpqewva6CtsyvIESmlVHA4mghEZLmI5IlIvojcF2D/pSJSLyI77J/vORmPv8npcRQ+cA23nZ+Np9uwr6zhbH20UkoNKY4tXi8iLuBh4HKgGNgiIquMMft6HfquMeYjTsVxKpPTYwEoqmlhwfjkYIWhlFJB42SJYBGQb4w5bIzpAFYC1zr4eWckPT4KgIqG9iBHopRSweFkIsgEivyeF9vbejtfRHaKyL9EZJaD8QSUEOUmKjyMisa2s/3RSik1JDhWNQRIgG2m1/NtwARjTJOIXA28BEzt80YitwO3A4wfP35wgxQhIz6K41oiUEqFKCdLBMVAlt/zcUCp/wHGmAZjTJP9eDUQLiJpvd/IGLPCGJNjjMlJT08f9EBHJURqiUApFbKcTARbgKkiMlFEIoCbgFX+B4jIaBER+/EiO55qB2MKKCMhStsIlFIhy7GqIWOMR0TuAtYALuBxY8xeEbnD3v8o8HHgyyLiAVqBm4wxvauPHJcRH8m6Bi0RKKVCk5NtBN7qntW9tj3q9/gh4CEnYxiIUQlRNHd00dTuIS7S0V+JUkoNOSE7sthfRnwkABVaKlBKhSBNBFglAoByTQRKqRCkiQCYNioeEdh8pCbYoSil1FmniQBIj48kZ0Iyr+0pD3YoSil11mkisC2fPYYD5Y0UVjUHOxSllDqrNBHYLppqjWPbrovUKKVCjCYC27jkaABK67TBWCkVWjQR2GIi3CTFhFNW3xrsUJRS6qzSROBnTGK0lgiUUiFHE4GfsYlRlNZpiUApFVo0EfgZmxRNWb2WCJRSoUUTgZ8xSVHUt3bS3O4JdihKKXXWaCLwk5lk9RzSBmOlVCjRROBnTKKVCEq0wVgpFUI0EfgZk2hNPlemDcZKqRCiicDP6MQoRKBUG4yVUiFEE4GfcFcYGfGR2oVUKRVSNBH0YnUh1USglAodmgh6Gauji5VSIUYTQS9j7NHFxphgh6KUUmeFo4lARJaLSJ6I5IvIfSc5bqGIdInIx52MZyDGJkXT7ummprkj2KEopdRZ4VgiEBEX8DBwFTATuFlEZvZz3M+ANU7FcjrGJtldSLXnkFIqRDhZIlgE5BtjDhtjOoCVwLUBjvsq8DxQ4WAsAzY2yTuoTBuMlVKhwclEkAkU+T0vtrf5iEgmcD3w6MneSERuF5FcEcmtrKwc9ED9TUqPQwT2lTY4+jlKKTVUOJkIJMC23i2wvwG+aYzpOtkbGWNWGGNyjDE56enpgxZgIHGRbqZlxLOjqM7Rz1FKqaHC7eB7FwNZfs/HAaW9jskBVooIQBpwtYh4jDEvORjXKc3LSmLNvnKMMdixKaXUiOVkiWALMFVEJopIBHATsMr/AGPMRGNMtjEmG/gH8JVgJwGA+eOTqGvppLC6JdihKKWU4xxLBMYYD3AXVm+g/cCzxpi9InKHiNzh1OcOhrlZSQDsKtbqIaXUyOdk1RDGmNXA6l7bAjYMG2M+42Qsp2N8SgyAjjBWSoWEAZUIRORuEUkQy59EZJuIXOF0cMESG+kmIcpNuc45pJQKAQOtGvqcMaYBuAJIBz4LPOBYVEPAmERdv1gpFRoGmgi8XWeuBv5sjNlJ4O6hI8boxCjKGzQRKKVGvoEmgq0i8jpWIlgjIvFAt3NhBd+YxCjKtUSglAoBA20s/jwwDzhsjGkRkRSs6qERa3RiFJVN7XR2dRPu0klalVIj10CvcOcDecaYOhH5FPBdoN65sIJvdEIUxkBFY3uwQ1FKKUcNNBE8ArSIyFzgv4GjwJOORTUEjLYXsteeQ0qpkW6gicBjrJVargV+a4z5LRDvXFjBNybRmoVUxxIopUa6gbYRNIrIt4BbgYvsNQTCnQsr+LJSrERwpKo5yJEopZSzBloiuBFoxxpPUI41nfQvHItqCIiJcDM+JYa8443BDkUppRw1oERgX/yfBhJF5CNAmzFmRLcRAEwbFc/Bck0ESqmRbaBTTNwAbAY+AdwAbBoK6ws7bfroeI5UNdPuOelyCUopNawNtI3gO8BCY0wFgIikA29iTR09Yk0bHY+n23CkqpnpoxOCHY5SSjlioG0EYd4kYKs+jdcOW+eMsjpG5Wn1kFJqBBtoieA1EVkDPGM/v5Fe00uPRGOTrLEEFQ06qEwpNXINKBEYY74hIh8DlmJNNrfCGPOio5ENAXGRbtxhQm1LR7BDUUopxwx4YRpjzPPA8w7GMuSICEkxEZoIlFIj2kkTgYg0AibQLsAYY0Z8C2pyTDi1zZ3BDkMppRxz0kRgjBnR00gMRLKWCJRSI9yI7/nzQSXFhFPX0slre8qob9GSgVJq5HE0EYjIchHJE5F8EbkvwP5rRWSXiOwQkVwRudDJeM5EckwER6qbueOpbfzhnYJgh6OUUoNuwI3Fp8uemO5h4HKgGNgiIquMMfv8Dvs3sMoYY0TkXOBZYLpTMZ2JpNhwOjzWYmzvFVQHORqllBp8TpYIFgH5xpjDxpgOYCXWNNY+xpgme3prgFgCN0wHVXJMhO/x7uI66lu1ekgpNbI4mQgygSK/58X2th5E5HoROQC8Cnwu0BuJyO121VFuZWWlI8H2JznmxGzb3QY2HdZSgVJqZHEyEUiAbX3u+I0xLxpjpgPXAT8O9EbGmBXGmBxjTE56evogh3lySXaJIDPJWp9gf5lON6GUGlmcTATFQJbf83FAaX8HG2PeASaLSJqDMZ02b9XQ1FFxJMeEU9mkK5YppUYWJxPBFmCqiEwUkQjgJmCV/wEiMkVExH68AIjAmtBuyPBWDWWnxpIeH0mlLmavlBphHOs1ZIzxiMhdwBrABTxujNkrInfY+x8FPgbcJiKdQCtwo1/j8ZCQHh+JO0yYNiqe/IomKjQRKKVGGMcSAYAxZjW9Zim1E4D38c+AnzkZwweVFBPB6rsvYmJaLFsKaygs1DWMlVIji6OJYKSYZq9L4K0aMsZg12gppdSwp1NMnIb0uEjaPd00tHmCHYpSSg0aTQSnISMhEkAbjJVSI4omgtOQHqeJQCk18mgiOA3p8XYiaNJEoJQaOTQRnIaMeGsN45La1iBHopRSg0cTwWlIiHYzOzOBlVuOUd/SyRAb8qCUUmdEE8FpEBG+9qGpHK1uYe6PXueJ9wuDHZJSSn1gmghO0+UzR3HHJZMBOFylg8uUUsOfJoLTJCLcd9V0JqbFUqtLVyqlRgBNBGcoKSac2mZd1F4pNfxpIjhDyTER1LZoIlBKDX+aCM5QckyElgiUUiOCJoIzlBwT3qONoLa5g3ZPVxAjUkqpM6OJ4Awlx0bQ2tlFm/1z+a/f4Qer9gU7LKWUOm2aCM6QdwnL2pYOXt93nKqmdl7cXkx9q/YkUkoNL5oIzpB3Ccva5k5Wbj5GQpSbts5uXtpeEuTIlFLq9GgiOEPJsVaJ4KlNR3m/oJo7L5vCmMQodhbVBTkypZQ6PZoIzpC3auhvm44xNyuJz104kZTYCOq0akgpNcxoIjhD3qohgO9cPYNwV5iOLVBKDUuOJgIRWS4ieSKSLyL3Bdj/SRHZZf+8LyJznYxnMCXZJQKAhdnJ9rZw6v26lO4va6CopuWsx6aUUqfDscXrRcQFPAxcDhQDW0RklTHGv4/lEeASY0ytiFwFrAAWOxXTYIpwh3Hb+RNYNmOUbyH7pJhwals62FBQTXp8JFf99l3cYUL+/VcHOVqllOqfY4kAWATkG2MOA4jISuBawJcIjDHv+x2/ERjnYDyD7kfXzu7xPDkmgvrWTm5+bKNvm6db1yxQSg1tTlYNZQJFfs+L7W39+Tzwr0A7ROR2EckVkdzKyspBDHFwJUaHo9d9pdRw42QikADbAl4mReQyrETwzUD7jTErjDE5xpic9PT0QQxxcCX7tRt4Rbi1PV4pNbQ5eZUqBrL8no8DSnsfJCLnAn8ErjXGVDsYj+OSY8P7bOvwdNPS4QlCNEopNTBOJoItwFQRmSgiEcBNwCr/A0RkPPACcKsx5qCDsZwVidEnSgTfXD6dWxaPB6CqUbuUKqWGLscSgTHGA9wFrAH2A88aY/aKyB0icod92PeAVOD3IrJDRHKdiuds8B9b8JkLsrl8xigAKpvagxWSUkqdkpO9hjDGrAZW99r2qN/jLwBfcDKGs8nbRpASG0F0hIu0uEgAqjURKKWGMG3JHEQJ0eGIwNikKADS4q3EUNWkVUNKqaFLE8EgcoUJCVHhjEmMBqySAUCVlgiUUkOYo1VDoehTS8Yzc0wiAJFuFwlRbk0ESqkhTUsEg+wbV07nmnPH+J6nx0fy5r7jbD5SE8SolFKqf5oIHPaNK6fT2W342WsHgh2KUkoFpInAYctnj2bZjFEcrmzqs+/1veU8u6UowKuUUurs0URwFkxOj6W2pZOa5p69h/7wzmEeebsgSFEppZRFE8FZMDkjDoACv1KBMYb8iiZdyEYpFXSaCM6CKelWIvCvHqpu7qC+tZP61k48Xd3BCk0ppbT76NkwNimaSHcYBZXN7Cmpp9sYWjq6ADAG6ls7SbVHISul1NmmieAscIUJE9Ni2Xq0ln/uLKWzq5s7Lpns21/bciIR/PHdw6zNq+DpLywJVrhKqRCjVUNnyccWjGPr0VrK6tuoaurgJ6/u9+3zbyfYUljDxsM1dOkKN0qps0QTwVly2wUTGJcczdSMOJbPGg1AQpRVIKv1601U0dhOV7ehslFHIyulzg6tGjpLIt0unv3S+YSJkB4fSWF1M60dXXzkd+t7lAgqGqwEUFrfyujEqD7vU9PcweYjNSyfPfqsxa6UGtm0RHAWjU2KZnRiFK4wYXJ6HJPt3kQ1zZ2A1aXUWxIoq2sL+B5PbTzKHU9tpU67nSqlBokmgiCKjnAR6Q7zXdTrWjrpsLuSltW3BnzNkapmwKpC8negvIHrHn6PxrZOByNWSo1EmgiCLCU2gprmDvaU1PP33BPTTZTVBy4RFFbbiaChZyLYUFDNjqI6Dlc2OxesUmpE0jaCIEuOiaCwupnP/WVLj7v8/koEhb4SQc9EUW4njgPlDfz5vSPc/59ziInQr1cpdWpaIgiy6AgXWwpreySBzKRoSgO0EdS3dFLbYlX99K4aKrUTwT93lvHSjlL2ljac9HM7PN3c+9xOjlW3fNBTUEoNc44mAhFZLiJ5IpIvIvcF2D9dRDaISLuI3OtkLEPV+ZNSSYuL5P7r5/i2zctKoqCiie3Hansce7TmRLVP76qhsjqrBJF3vBGweheV1LVy6582BeyKWlDZxD+2FvPvA8cH7VyUUsOTY4lARFzAw8BVwEzgZhGZ2euwGuBrwP85FcdQd++V55D73WXcsni8b9uXL51MfJSbT/1xk291s4a2Tl7ZVQaAO0yoaGxj+7FablqxgdaOLl+bgveiX9Pcwbdf2M27h6p4+2Bln8+tttdRLu+nLUIpFTqcrEReBOQbYw4DiMhK4Fpgn/cAY0wFUCEi1zgYx7Dx4M3z2VfawOzMRP76hcVc/qu3ufq375IcE8GHZmSw4p3DxES4mJIRR0VjO2/sO87GwzXsKq6jvKHnBb2qsZ2Nh6sBAvYkqm62u6lqIgjo0PFGEmPCyYjvO5ZDqZHGyaqhTMB/1ZVie5vqx0fnjuW+q6YDMDk9jk+cl0VFYzt5xxt5dksRs8YmsPbeS8lKiaGqsZ28cqsaaN3Byj5TUvz7QAXtHqsramld34Znb8nhTEsE1U3tNLd7zui1w8Htf93KL9ccDHYYSp0VTiYCCbDtjCbQEZHbRSRXRHIrK/tWc4xUP7l+Ni/fuRSwpq1eMimVUQlRZMRHUtHYzgE7Ebyxz6rnF7/f+O6SegDCXRKw4bnantaid0lioG5+bCP3r95/6gOHqarGdkr76bml1EjjZCIoBrL8no8DSs/kjYwxK4wxOcaYnPT09EEJbjgId4UxNyuJccnRAJw3IRmAUQlRNLV7KLHv9PMrrHUOJqbG+l7b1W1whQkLxicHvKBVN50oERjTf37eerTWd6xXc7uHg8ebfIPbRprubkNTh8fXjqLUSOdkItgCTBWRiSISAdwErHLw80asRRNTgBOJYNmMUb5941NiAGs5TO9xXmMSoxifEhOwash7kevo6mbD4Wo6PH0Xx+ns6ubmxzay4t3DPbZ7V1obqRPjNXd4MOZEO4pSI51jicAY4wHuAtYA+4FnjTF7ReQOEbkDQERGi0gx8HXguyJSLCIJTsU0XH3xokl866rpjEqwGi6nZMQxa6z1a/p/V0xjxpgEHv/MQjLirTUNXGFWHdG45GjGJEVT0dje50Jf1dzhq0q65bFN/Pm9I30+t6S2lQ5PN0U1PccaHDxuJYLeYxlGiia77aO6qeOkpaUzUVDZxB90neohraCyiQ0F1cEO46xydOipMWY1sLrXtkf9HpdjVRmpk5gxJoEZY3rmx2duX8KmwzVcPnMU186z2uBTYiMAyE6NoaCymazkGDKTojAGjje0kZUSgzGGN/dXUFbXysTUWA7b1Tv7y/oOQDtiT2fRu43hUIXVNlHf2km7p4tIt2twTzjIGtusRODpNjS0ekiMCR+09/7H1mIeWVfAjQuzSIqJGLT3VYPnobfy2VJYw/pvfijYoZw1OrJ4mEqICufymaN6bEu3uzrOHJsIQFZKDOOSraqj5b95h7cPVvLKrjK++GQuFY3t5GQn+157uKqZr/99BzuL6nzbjtpJovd0F/nHT6y9PFjVQ09vOsrFP19L9ykW5OnqNr5usU7xJgKAqkGuHvJNM97P7LJD0Y6iOtYfqgp2GGdNXUsH9S2hNXmjJoIRZNnMDB6+ZQFLJ6cCkJUSzaKJKfzo2lmMTYrmnr/v4OdrDviOn5AaS8H9V/Pp8yewq7ieF7aX8Py2Yt/+Qnv6iYrGdjrtWVG7ug17Sut9i+pUNrZT0dB2xn847+dX8YNVe1m1o5RjNS0Bq5v8q2de3V3GTSs2ctAeQe0E/3EXg91g7J0jqr+5pIaiX71xkB/+c2+wwzhrGts8NHV4TnlTMpJoIhhBIt0urjl3DKPsBW2yU2MJd4Vx2/nZPPKp80iMDqeoppUPT88AIEwEV5hwzugT1U7bj1klgvyKRt/F1lu1BPDOwUqON7Rzy+IJAPz8tTwW3f9vvvvyHt97vLS9hB+s2kt+RSM/fXUftz+Z2yPOopoWXt9bjjGG//fcTv7yfiGbjtRY+2p7tke8vrecuT983TdV9167W2xJgAbwgaprOXndf48SQZNDJYJhNJCvsrHd1904FDS1W50FmjtG7jiZ3nR6yhHo4qnpPPG5RczLSvJtm5IRx9p7L6Wts4twVxjPbyvm6jljADhndLzvuN0l9Xz68c2+aSncYYKn21BW38aP/rmP3KO1pMVF8snF43n07QI22NU0u4pPVCk98K8DlDe08frechrbPDS2e3hyQyGuMOGTiyfwvZf3sDavkmvmjCE5JqLH6Obi2hYWZp/o/fTPXWU0tHnYfqyOy6ZnsN8eO3GmVVJtnV3M+9Eb3LQwiwc+dm7AY5r8Bsr17jr7QflKBKeRyDxd3TybW8wncsYR7vpg925/3VDIrMxEFoxPPuWxXlVN7dS1dPi6JI903huBpnYP8VGD1z40lGmJYARyhQmXTEtHpO8fbVS4C1eYcENOFnGR1n3AjDHxTEqL5eZF1rCPtw9W8rEFVhv+pedYpYcXt5fw+r7jxEe5uXvZVMb4LaM5MS2Wlo4uwLpTL29oY1F2CqX1bTTaF9XvvbyX77y4hz+tP8Jm++7/1d1lvh5J3liKaqwLZENbJ6/tKWP9ISsh7bDbLg7YjdpnmgiK7RLHyi1FtNox9+ZfNVQ1iFVD7Z4u3+yxbx2o4Psv7+m3+qGmuYPvvrSb1o4u3s2v4tsv7ua9/MD19O8XVNHWGfhc/HV1G370yj5WvH34lMd6dXcbapo76DZW54BQ0GB///4lw5FOE4EiJsLNW/deyr1XnAPA9NHx/PKGubxxz8Xcf/1sAP626RiJ0eGs+a+LuXXJBNx+d6bXzBlDVVM7nq5uttgX+e9cM4O0uEjiIt18aHoG6fGRXDQ1jR+/so/mji7fJHuN7R7uWTaNNfdcTHp8pO9C/ZNX9nHHU9t8F85dxXXUNHf42hCqznCKi6LaE3fiq3aW9NxX00JrRxdNbR5EIDE6vM+6D/0prGru0dAeiH/yOlDeyBMbjnK0V9fczq5u1uZVsC6vgqc2HmP7sVqK7WMCTQey+UgNtzy2iee2FvfZ11tpXSudXYadxSeP01+tXRIAKzmNdN3dxlci1ESgQlJqXCQvfuUCXvjKBQBMHRVPRkIU2alWz6NPnz+BqPATXUU/c0E237pqOmPsLqpVTR1sOlJDfJSb2ZmJ/OS62Xz/P2by+08uYO29l/LrG+eRGB2OK0z40sWTfO9zzug4MpOiyUqOpqimleLaFl7YVkJSTLgvkewqrudA+Ykurm/sO87cH77OHrvNoLndw3df2n3Ki1WxXyLw7yv+Xyu3c9HP13Ljig2U1LURF+Fm/vgknsstZs3e8lP+7v7n5T185eltJz3Gm8Qi3Sf+7Lyjwr1e2VXKZ/+8xTdtSHFdqy/mQNOBPLGhEIAdx059cfeWvsrq23xtPqfiXyKqDfI62VuP1tDuOXXJ54No6ezC23wUSsu+ahuB6mF+gLrj1++5hDZPFwm96kt/8NFZALxpX7SOVjezZm85Syen4QoTls8e3eP4uEg3v7lpHgUVTUxIjWVsYhSl9W1kp1lTY2SlxLDtWC3Pbimi2xhe/dpFpMVF8FxuMW8dqOCfO60ZSqZmxHHIvoC+tL2E2ZmJrM+v4qmNx0iPi+Lg8UZuXJjFxdP6TkdSXNtChCuMS85JZ3vRiYbxl3aUsmxGBuvyKtlVXM/YxCgevHk+1z30Ho+vP8KVs06cy9ajNfx9SxGLJ6bysfPG0TVLpscAABf8SURBVNnVzdajtbR0dNHQ1tnn9+TlbSj2rwwqqGzick50A/YO1nvX7q5Z6pcIel+8a5o7WLPHSlK7S06dCPxLHzuL6rhi1uiTHG3xbyM5WQ+qDQXVFNe28ImcrH6P+SAqGtr4+KMbuP/6Ody8aPypX3CG/C/+TSN4UsXetESgTinCHdbvxQ1gtN1e8MjbBdQ0d/CZpdn9HnvZORl84SKrNDAr0xrvMCHFTgTJMZTWtbF6TzkLxieTmRRNpNvFkklWd9jncouZnB7LNL/G7dW7y+juNr4BcQ+vy+fV3WV8+s+bWX+oimc2H/N1be3uNpTUtjI2KYoF45M5Wt1iXUz3WonsJ9fN8X1WfFQ4CVHhXDAllX2lDb66/K5uw1ee3sazucX88vU8APaWNvjaSP539f5+u1p6q5kevGk+H507lrS4iD4lgiP2mtPei1BJbauvJ1XvqqEdRbV4ug0XTE4lv6LplFVlx2pacIcJ7jDhqU3HuPPpbTybW3TS11T6JYL+SgRPbTzKzY9t5Bv/2DWgtoozUVrfhjHWOZyOFe8U8Ma+4/z4lX088X5hj33P5hbxzOZjPbb5Vwc5XTXk6ermd/8+FHAKmLNNE4H6wDISrKkt1uVVMjszgcW95jzqz405Wdy6ZALREVZ105WzRtPVbcivaOIyu4srWPMojU6IwtNtWDQxhfQ46/Mi3WGU1rexvaiOffbSnB2ebqZkxJERH8nXVm7nWy/s5qlNR2ls6yTnp2/yyq4yxiXH+HpU7Syqs7qoZiUxOjHKt93tshra52Qm0tju8d1Nbyio5nhDO3Ozkiitb6O6qd3XLgLwzOYinni/kOe3FvODVXt7dFPdcayO2AgXl88cxYM3z2dqRnyfRHC4qufz0nr/qqGeDeS7ixsQgZsWjafbcNLlSV/eUcLaAxVkpcTw1Q9N5f38Kl7dXcZPX91/0gTiXzUUqNqtoLKJH7/iW2Kkz3QkxbUtPPTWoR6J1FuddzrOdNr0372Vz+Prj/DM5mP8a09Zj31/fq+wz9QqPUoEDiWCfaUNeLq62VVSzy/fOMgFD7wV9Hm7NBGoDyw1NtL3+IacrIC9lQJZNnMUP75utu/5nHGJLJ1i3ZFfds6JRCAiXDg1DYCcCSmk23Mq3bgwiwh3GK/sKmV/eQPxds+j6+dn8snFE3wXrrcPWtU93ufp8ZGcOy4Rd5jw+3X57Cyu5z/OtbrSehOBdy3nWfYo7V3Fddz6p0187i9biI9yc8+yqdb2knq2FNYwITXG9/ndBr794m7+8n4hf3jnMMcb2qhoaOOfu0r5RE6WrwvmlIw4CiqaMMbQ1tnFu4cqKazqeSE9dLzJF3fvqqHdJfVMTItlyaQUX4yB1Ld0cvfKHRwobyQ5Jpy7l00l97vL+NsXF1Pf2tnnrthfVVM77jAhJsLVJxE0tnXy5ae2Eh3h4g+3ngdYpcKPP/I+HnsA4gvbSvi/1w/6pjJ5eUcJH/ndel8vsIE6k4F49S2dNLZ52FJYQ0tHV5/R3MW1LRTXtvZI1j1LBIPfRrD9WC1XP/gul/1yne/mBWDVzjOamHnQaCJQH5h/33Lv2IQz9T8fmcnXPjSFGWPie2xfPms0ke4wzp+c6ksEC7NTuHRaOi9sK6GoppXPLM3mzssmc8ui8Xxy8XjmZiWxdEoq247Wst6v62V0hIvYSDe3nj+BLYW1JMWEc5Nd7zzXTgTebq/TRsUT4Qrj128c5N1DVSyYkMQ3rjyH8yYkIwK7iurZU1LPvKwkX5WVK0xo93QTFR7GA/86wBW/foc/v1+Ip9vwmQuyfXFMHxNPoz2l95MbCrn1T5vp6Or2JRSr15J1pzg1I46a5g7qWzv564ZCmto97C2tZ05mIhnxUYxJjGJXceA77U1HTjSKe6ccSYqJ4ILJaZw/KZXH3j3sa4Q1xvCFJ7Zw19+shu+qxnZS4yJIiY2gprmDN/cd5+G1+QD87LUDFFQ28/AtC3xjP17cXkLu0Vp22Xf9hfZ8Vfn2/FSbDlulp5e2l/guwMW1LVzz4Lu8YI9qr2nu4NY/beJo9Ylpzr13zMcbBn7n7K1S89ilkbL6Vl/JpL7VShItHV09ElyPRGD/H9hbWs9TG48G/Ix1eRV89KH1tHV2kVfeyFee3urrfhqINwEW1bTy+HqrNJIUE37aiXGwaWOxGhTZqTF0dhnS4iJPffBJTB+dwPTRfSegXTZzFNu/dzkxEW7mZSWRlRLNwuwUuo3hdbux+rwJyb5xDwAv37mU9wuqeC9/E4+sK2BSWiz3XD6N8+0pOO65fBobCqr55JIJvnEM3iTj7d4a4Q7jgimprMurZNHEFP72hSWE2YlvUlosa/MqKK1vY/bYROZlJTEhNYYjVc1sP1bHS3cu5d2DVfx09X4ee+cwSyen+RrGwaoK+/7Le3lhW3GPKpiLp6Xz6u4yFman8OZ+69wumZbOoYom7nx6G+vzq9hb2kBZfRtz7HaWc8cl+hYjqm3u4M/vFzIuKZrrF2Sy4XA1ke4wnv7CYialx/X4vX7lssnc+qfNvLithCtmjebN/cd5c38FADPG5PPWgQrGp8b4xhN8wR4lPnNMAi9uK+H6+ZksnZKGMYb4SLfv4rn+UBULxidTaJcE/rG1hL9uPOqr439ig1V9tvrui9hQUM3e0ga+/uxORidEUVDZxLuHqngut5g39x/n/z4x15cQy+qtO/iBlDqLa3t3zTVUNbWTkRDVY19xbSupcZHUt3Zy2G6jcYeJLync+9wu9pc1MDk9zvd/x+u5rcXsKq7n0PEm/p57jNW7rcb7xRNTuXXJBN//Fa99pQ0kxYTT0tHF4apm0uIiWJidwo6iWjo83Xz7xd3cfvEkpo3qeSPkNE0EalCsuedixz8jJsL67zptVDzv/rc1M+Q1c8bQbQyxEW4umtq3l9DC7BQmpcdyuLKZqaPi+I+5Y337EqLC+dfdF/W5qBz536t7bHv80wupaGwnKSa8xx/20ilpPLnBulOclZnABZOt6qvncouYlhHP9NEJTEmP4w/vFFDV1MF183uu1JoWF8ml52TwwvYSUmIiGJUQycLsFO64ZDJHa5q55lzrwnzrkglcPC2dP64/wvr8KmIjXKzcUkS4S/iQ3ZZy7rgk1uw9Tnl9G//5+/d8U1hUNrWz8XAN501IJie7b9vNhVPSmDsukYfW5vPwunyKaloZlxxNfUsnv1iTx6yxCfz0ujn8fM2BHvXzX356K22d3b5BiCLChLQY9pRY1R3rD1XxtQ9P9c1X5U1oYK2vsflIDY3tHt4vqKLAvvjGRbr5x9ZiXwP1kxsKaWjz8PbBSl+JoK2zm/rWzpPO3Pri9mKmjYr3DU70t+1YHQWVTT26ERfXtjI3K4lvvbDLdyEflRDlayPosEtL96/ezz+/eqHvdV3dxjcZX97xRt97rt5dzurd5UzNiOOCKWk9Pn9/eQOzxyZS3dzB/rIGxiXHMH98Ev/aU85bB47zj63FJEWH892PzOz3/JygiUANimBNRe12hXH9/P5nMg93hXH/9XO4acVGlvb6owQC3ln23hYWJr6eUf4+tmDciURgtyUAfCIny9eN0u0K47p5mfx9S1Gf7rQAN+SM4839x6lsbOcrl07mv5dba1a/8tWL6Oo2jE+JYX5WMh1d3Xzp4klMHxNPUnQEn/3LFr508WTfHb63ZPDw2nxK69tYcet5PLQ2n+e3FnO4qplvXHlOwN+PiPD1K87h049vBqyquQ9PzyC/oomKxnZuyBmH2xXGuZmJrMuzRnnfdv4E8sobiYt095iqYkJKLHtKGjh/Uiobj1Rzz993BGxgvvvDU1k8MYWcn77J1qO1VDV1MH10PPPHJ/HS9lLfBIcN9oU4r7yxx2SEi+//N9fNyyQ6wkVMhItPX5DtW6ujvrWTe5/bxUVT0xifEkN8lJuM+EjCXWEcKG/kjqe29omnqLalx0UdrA4Qeccb2XS42jcIcXdJPRUNbWTYn7WruM432jqvvIHdxfUsnzWaxZNS+OE/9/FeQVWPRODp6ubg8SY+c0E2FQ1t7C9rICslhnlZ1u/wD+9YI743Hanh8fVH2FvawGeXZjM788T/LadoIlAj3pJJqaz/5mWMTuh7Mf8gzh2XyNSMODq6ukmM7r977b1XnsMXL57kq37y9+EZo8hMiqakrtV3MfdyhQnnTbDu4qPCXHzr6hmAVY+/8vYl5Ew4cRGeOy6JCHcYf9tsjQC/bHoG247V8ai9CM4VvaYs93fx1DSun5/JqIQoPn/hRIAeVVgA187P5MG3rLaBz184kQmpsX3e55zR8azNq+ChW+bzizV5rNxidU2dlGate/G1D0+luKaF8yYk43aFcd74ZLYeraWzyzAnM5FP5GTxzOYiMuIjWTwp1Tdu5ODxRhrbPL6SXbunmxe2FxPuCqPd083uknr++vnFgFUS6eo2vJ9fTcv4LrKSY3j8Mwvp7Ormop+vBWBhdjJbCmsBqx2muLaFA+UNvsQDVvfh7cfquPmxjXQbq6rwb5uOse1YLctmjCL3aC0/eXUfEa4wMhIiWZtXSXVzBxdMSeW287N5dVcZ6/Or+caVVgIoqm3lG8/tpMPTzYwx8STZa1xkJUczNyuR5Jhw34SPu0vq2V1SjztM2FNSzytfu/ADzzF1KtpYrELCuOSYHtNiDAYR4Xe3zOc3N8476XFR4S7fHWtvrjDhs0uzcYWJr6F6IJ+7ZFJqj/NJjAnny5dMpqvbsGzGKMJdYVxg12dPSotlSkZcf2+HiPDrG+dx31XT+z1mcnocczITSYmN8C2P2tsXL5rEa3dfTGpcJD/x6w1m3dUm8MWLJvKrG+f5Rqefl51MQWUzx2pamJwRx4LxyeR+dxkbv/VhXy+uqPAw8iuaKK1vZd446/czLjmaXd+/kj0/uJJvXz2Ddw9V8fKOEnYW1fHyjhJErCVYNx+pISslmtGJUb51vwF+/vG5vsdZKdEcq2n1NWJ7bT9qJQrvVFD/OT+TCFcYj79XyBW/foebVmyksKqFR29dwKKJKb5uwN5kvnRKGruL61j2q7eZ+b013Pb4JvLKG7lmzhgumZbBOXYbQFZKDJFuFzcstEqQ3t9tdmoMD948n7zjjXznxd2Oj6jWEoFSH0Cghu3T9bmlE1k2YxRjk6JPffBJfPnSyZTVt3Lb+dkA5GQnExfp5iNzxw64S+/JPPCxOdQ0d/T7XtERLsbb05G4XWH86oa5PLKugBsWZnGrHZO/D03P4OevWYPyvInK29lg8cRUFk9MYWF2Cg/ZvZRmZyZy2fQMLpyS5ht78qkl43lxezF3r9zhe9+rZo9mS2ENVU0dvlHI/jFPTIvl65dPI9IdRll9G09tPEppXSvjU2L4wUdnUlbfRntnN89vK6alo4vC6mZmjk1gXHI0m4/UkJkUzYM3z+fSc9JJiAqnsMqaEiVnQrKvivDaeWPZUFBNbKSLUQmRvJdfzf3Xz/F1QsjJTuGSaelcaFcdfWrxBJ58/yj3XD6Vx945wj2XT2PZjAzuvGwyD68tYNuxOuZkJnLpOem+FQkHkwz2mqxOy8nJMbm5uac+UClFRWMbyTERjlctnKnX95bzwGsHeOrziwMmwgPlDSz/zbsAvPn1SwKWbNo6u3g2t4i4SDcdnm6WTkkj3BVGdLirxzKjhyubiI5wMSbxxOdUNrZzyS/W0tLRxe8/uaBP9+eXd5SwoaCaBz52Lt97eQ9PbjjKK1+9sEe9fVtnF9uO1bJkYmqfXkJgNSrvL2tg1tiEkybkts4uIt1hfY5Zl1fB/av309rZxW1Lsvmi3zxdp0NEthpjcgLu00SglBrKXttTzoIJSWTED24bj9eaveXUtXRw48KTz2HU0uGhsrE9YPvIcHCyRODobYKILBeRPBHJF5H7AuwXEXnQ3r9LRBY4GY9SavhZPnu0Y0kArPEcp0oCYHVfHq5J4FQcSwQi4gIeBq4CZgI3i0jvzrFXAVPtn9uBR5yKRymlVGBOlggWAfnGmMPGmA5gJXBtr2OuBZ40lo1Akoh8sDkKlFJKnRYnE0Em4D/HbbG97XSPQURuF5FcEcmtrKwc9ECVUiqUOZkIAjWP926ZHsgxGGNWGGNyjDE56el9pxFQSil15pxMBMWA/3JF44Dec60O5BillFIOcjIRbAGmishEEYkAbgJW9TpmFXCb3XtoCVBvjCnr/UZKKaWc49jIYmOMR0TuAtYALuBxY8xeEbnD3v8osBq4GsgHWoDPOhWPUkqpwBydYsIYsxrrYu+/7VG/xwa408kYlFJKndywG1ksIpVA4OWCTi0NqDrlUcODnsvQpOcyNOm5wARjTMDeNsMuEXwQIpLb3xDr4UbPZWjScxma9FxObmjORKWUUuqs0USglFIhLtQSwYpgBzCI9FyGJj2XoUnP5SRCqo1AKaVUX6FWIlBKKdWLJgKllApxIZMITrVIzlAnIoUisltEdohIrr0tRUTeEJFD9r/JwY4zEBF5XEQqRGSP37Z+YxeRb9nfU56IXBmcqAPr51x+ICIl9nezQ0Su9ts3JM9FRLJEZK2I7BeRvSJyt7192H0vJzmX4fi9RInIZhHZaZ/LD+3tzn4vxpgR/4M1xUUBMAmIAHYCM4Md12meQyGQ1mvbz4H77Mf3AT8Ldpz9xH4xsADYc6rYsRYx2glEAhPt780V7HM4xbn8ALg3wLFD9lyAMcAC+3E8cNCOd9h9Lyc5l+H4vQgQZz8OBzYBS5z+XkKlRDCQRXKGo2uBJ+zHTwDXBTGWfhlj3gFqem3uL/ZrgZXGmHZjzBGseagWnZVAB6Cfc+nPkD0XY0yZMWab/bgR2I+1Fsiw+15Oci79GcrnYowxTfbTcPvH4PD3EiqJYEAL4AxxBnhdRLaKyO32tlHGnq3V/jcjaNGdvv5iH67f1V32utuP+xXbh8W5iEg2MB/r7nNYfy+9zgWG4fciIi4R2QFUAG8YYxz/XkIlEQxoAZwhbqkxZgHWOs93isjFwQ7IIcPxu3oEmAzMA8qAX9rbh/y5iEgc8DzwX8aYhpMdGmDbUD+XYfm9GGO6jDHzsNZnWSQis09y+KCcS6gkgmG/AI4xptT+twJ4Eav4d9y7xrP9b0XwIjxt/cU+7L4rY8xx+4+3G3iME0XzIX0uIhKOdeF82hjzgr15WH4vgc5luH4vXsaYOmAdsByHv5dQSQQDWSRnyBKRWBGJ9z4GrgD2YJ3Dp+3DPg28HJwIz0h/sa8CbhKRSBGZCEwFNgchvgHz/oHarsf6bmAIn4uICPAnYL8x5ld+u4bd99LfuQzT7yVdRJLsx9HAMuAATn8vwW4lP4ut8Vdj9SYoAL4T7HhOM/ZJWD0DdgJ7vfEDqcC/gUP2vynBjrWf+J/BKpp3Yt3BfP5ksQPfsb+nPOCqYMc/gHP5K7Ab2GX/YY4Z6ucCXIhVhbAL2GH/XD0cv5eTnMtw/F7OBbbbMe8Bvmdvd/R70SkmlFIqxIVK1ZBSSql+aCJQSqkQp4lAKaVCnCYCpZQKcZoIlFIqxGkiUCFLRN63/80WkVsG+b2/HeizlBqKtPuoCnkicinWLJUfOY3XuIwxXSfZ32SMiRuM+JRympYIVMgSEe8sjw8AF9lz1t9jT/r1CxHZYk9Y9iX7+Evtee//hjVQCRF5yZ4IcK93MkAReQCItt/vaf/PEssvRGSPWOtL3Oj33utE5B8ickBEnrZHzCrlOHewA1BqCLgPvxKBfUGvN8YsFJFI4D0Red0+dhEw21hT/gJ8zhhTY08HsEVEnjfG3Ccidxlr4rDe/hNrErS5QJr9mnfsffOBWVhzxbwHLAXWD/7pKtWTlgiU6usK4DZ7KuBNWMP7p9r7NvslAYCvichOYCPW5F9TObkLgWeMNRnaceBtYKHfexcba5K0HUD2oJyNUqegJQKl+hLgq8aYNT02Wm0Jzb2eLwPON8a0iMg6IGoA792fdr/HXejfpzpLtESgFDRiLXHotQb4sj21MSIyzZ71tbdEoNZOAtOxlhT06vS+vpd3gBvtdoh0rKUvh8TMlyp06R2HUtZMjx67iucvwG+xqmW22Q22lQReBvQ14A4R2YU18+NGv30rgF0iss0Y80m/7S8C52PNJGuA/zbGlNuJRKmg0O6jSikV4rRqSCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAppUKcJgKllApxmgiUUirE/X/HyvbLCPZV9AAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "},{"metadata":{},"cell_type":"markdown","source":"<b>Identify the first four misclassified samples using the validation data:</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nmax_num_of_items = 4  \nvalidation_loader_batch_one = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n\nfor i, (x_test, y_test) in enumerate(validation_loader_batch_one):\n    model.eval()\n    z = model(x_test)\n    _, yhat = torch.max(z.data, 1)\n    \n    if yhat != y_test:\n        print(\"Sample : {}; Expected Label: {}; Obtained Label: {}\".format(str(i), str(y_test), str(yhat)))\n        count += 1\n        if count >= max_num_of_items:\n            break","execution_count":null,"outputs":[{"output_type":"stream","text":"Sample : 304; Expected Label: tensor([1]); Obtained Label: tensor([0])\nSample : 378; Expected Label: tensor([1]); Obtained Label: tensor([0])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."},{"metadata":{},"cell_type":"markdown","source":"<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."},{"metadata":{},"cell_type":"markdown","source":"Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}